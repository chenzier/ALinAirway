{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "617a41aa",
   "metadata": {},
   "source": [
    "# Generate pre-cropped EXACT09 and LIDC-IDRI for faster training 切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50c27250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import SimpleITK as sitk\n",
    "\n",
    "\n",
    "# build the raw_data_dict for train\n",
    "\n",
    "raw_data_dict = dict()\n",
    "\n",
    "# # LIDC-IDRI data\n",
    "# LIDC_IDRI_file_path = \"/home/cs22-wangc/now/NaviAirway/LIDC-IDRI\"\n",
    "# LIDC_IDRI_raw_path = LIDC_IDRI_file_path+\"/image\"\n",
    "# LIDC_IDRI_label_path = LIDC_IDRI_file_path+\"/label\"\n",
    "\n",
    "# LIDC_IDRI_raw_names = os.listdir(LIDC_IDRI_raw_path)\n",
    "# LIDC_IDRI_raw_names.sort()\n",
    "\n",
    "# LIDC_IDRI_label_names = os.listdir(LIDC_IDRI_label_path)\n",
    "# LIDC_IDRI_label_names.sort()\n",
    "\n",
    "case_names = []\n",
    "\n",
    "# for case in LIDC_IDRI_raw_names:\n",
    "#     temp = case.split(\".\")[0]\n",
    "#     #print(temp)\n",
    "#     case_names.append(temp)\n",
    "#     raw_data_dict[\"LIDC_IDRI_\"+temp]={}\n",
    "#     raw_data_dict[\"LIDC_IDRI_\"+temp][\"image\"]=LIDC_IDRI_raw_path+\"/\"+case\n",
    "\n",
    "# for case in LIDC_IDRI_label_names:\n",
    "#     temp = case.split(\".\")[0]\n",
    "#     #print(temp)\n",
    "#     if temp in case_names:\n",
    "#         raw_data_dict[\"LIDC_IDRI_\"+temp][\"label\"]=LIDC_IDRI_label_path+\"/\"+case\n",
    "\n",
    "# LIDC_IDRI_data_dict = raw_data_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# EXACT09 train data\n",
    "\n",
    "raw_data_dict = dict()\n",
    "\n",
    "EXACT09_file_path = \"/home/cs22-wangc/data/Airway/EXACT09_3D\"\n",
    "EXACT09_train_raw_path = EXACT09_file_path+\"/train\"\n",
    "EXACT09_train_label_path = EXACT09_file_path+\"/train_label\"\n",
    "\n",
    "EXACT09_raw_names = os.listdir(EXACT09_train_raw_path)\n",
    "EXACT09_raw_names.sort()\n",
    "\n",
    "EXACT09_label_names = os.listdir(EXACT09_train_label_path)\n",
    "EXACT09_label_names.sort()\n",
    "\n",
    "case_names = []\n",
    "\n",
    "for case in EXACT09_raw_names:\n",
    "    temp = case.split(\".\")[0]\n",
    "    case_names.append(temp)\n",
    "    raw_data_dict[\"EXACT09_\"+temp]={}\n",
    "    raw_data_dict[\"EXACT09_\"+temp][\"image\"]=EXACT09_train_raw_path+\"/\"+case\n",
    "\n",
    "for case in EXACT09_label_names:\n",
    "    temp = case.split(\"_\")[0]\n",
    "    if temp in case_names:\n",
    "        raw_data_dict[\"EXACT09_\"+temp][\"label\"]=EXACT09_train_label_path+\"/\"+case\n",
    "\n",
    "EXACT09_data_dict = raw_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d48829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EXACT09_CASE01': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE01.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE01_label.nii.gz'}, 'EXACT09_CASE02': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE02.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE02_label.nii.gz'}, 'EXACT09_CASE03': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE03.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE03_label.nii.gz'}, 'EXACT09_CASE04': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE04.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE04_label.nii.gz'}, 'EXACT09_CASE05': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE05.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE05_label.nii.gz'}, 'EXACT09_CASE06': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE06.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE06_label.nii.gz'}, 'EXACT09_CASE07': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE07.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE07_label.nii.gz'}, 'EXACT09_CASE08': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE08.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE08_label.nii.gz'}, 'EXACT09_CASE09': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE09.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE09_label.nii.gz'}, 'EXACT09_CASE10': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE10.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE10_label.nii.gz'}, 'EXACT09_CASE11': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE11.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE11_label.nii.gz'}, 'EXACT09_CASE12': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE12.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE12_label.nii.gz'}, 'EXACT09_CASE13': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE13.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE13_label.nii.gz'}, 'EXACT09_CASE14': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE14.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE14_label.nii.gz'}, 'EXACT09_CASE15': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE15.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE15_label.nii.gz'}, 'EXACT09_CASE16': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE16.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE16_label.nii.gz'}, 'EXACT09_CASE17': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE17.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE17_label.nii.gz'}, 'EXACT09_CASE18': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE18.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE18_label.nii.gz'}, 'EXACT09_CASE19': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE19.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE19_label.nii.gz'}, 'EXACT09_CASE20': {'image': '/home/cs22-wangc/data/Airway/EXACT09_3D/train/CASE20.nii.gz', 'label': '/home/cs22-wangc/data/Airway/EXACT09_3D/train_label/CASE20_label.nii.gz'}}\n"
     ]
    }
   ],
   "source": [
    "# print(LIDC_IDRI_data_dict)\n",
    "print(EXACT09_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d353cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#当我们需要对一个3D图像进行处理时，可能需要将其分成多个小块，以便于对每个小块进行处理，比如使用卷积神经网络进行分类或分割等任务。\n",
    "# 这时，我们需要一个函数来将3D图像分成多个小块，这个函数就是crop_one_3d_img。\n",
    "def crop_one_3d_img(input_img, crop_cube_size, stride):\n",
    "    # input_img: 3d matrix, numpy.array\n",
    "    # input_img：输入的3D图像，为numpy.array类型。\n",
    "    # crop_cube_size：可以是一个int类型的值，也可以是一个长度为3的tuple类型的值，表示裁剪出来的小方块在3个方向上的大小\n",
    "    # stride：stride也可以是一个int类型的值，也可以是一个长度为3的tuple类型的值，表示在3个方向上移动的步长\n",
    "    assert isinstance(crop_cube_size, (int, tuple))\n",
    "    if isinstance(crop_cube_size, int):\n",
    "        crop_cube_size=np.array([crop_cube_size, crop_cube_size, crop_cube_size])\n",
    "    else:\n",
    "        assert len(crop_cube_size)==3#如果 crop_cube_size 是一个三元组，则检查其长度是否为 3\n",
    "    \n",
    "    #不能超过input_img的shape\n",
    "    crop_cube_size = (min(crop_cube_size[0], input_img.shape[0]),\n",
    "                      min(crop_cube_size[1], input_img.shape[1]),\n",
    "                      min(crop_cube_size[2], input_img.shape[2]))\n",
    "    \n",
    "    #检查 stride 是否为整数或 3 元组，类似于 crop_cube_size。如果它是一个整数，则将其转换为一个大小为 3 的 numpy 数组\n",
    "    assert isinstance(stride, (int, tuple))\n",
    "    if isinstance(stride, int):\n",
    "        stride=np.array([stride, stride, stride])\n",
    "    else:\n",
    "        assert len(stride)==3\n",
    "\n",
    "    #获取输入图像的形状并计算需要切割的总次数\n",
    "    img_shape=input_img.shape\n",
    "    \n",
    "    total=len(np.arange(0, img_shape[0], stride[0]))*len(np.arange(0, img_shape[1], stride[1]))*len(np.arange(0, img_shape[2], stride[2]))\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    crop_list = []\n",
    "    #现在，我们将开始对输入图像进行切割。\n",
    "    # 通过使用三个 for 循环，我们遍历整个输入图像，每个循环中获取一个立方体。\n",
    "    # 在每个迭代中，我们还检查当前位置是否可行，并相应地调整 x、y 和 z 的开始和结束索引。\n",
    "    for i in np.arange(0, img_shape[0], stride[0]):\n",
    "        for j in np.arange(0, img_shape[1], stride[1]):\n",
    "            for k in np.arange(0, img_shape[2], stride[2]):\n",
    "                # 接下来的代码是对于每个 i, j, k 的组合，判断裁剪的范围是否超出了原始图像的边界。\n",
    "                # 如果没有超出边界，就根据裁剪范围和步长计算出在裁剪后的图像中的范围；如果超出了边界，则在原始图像的边界处进行裁剪。\n",
    "                print('crop one 3d img progress : '+str(np.int(count/total*100))+'%', end='\\r')\n",
    "                if i+crop_cube_size[0]<=img_shape[0]:\n",
    "                    x_start_input=i\n",
    "                    x_end_input=i+crop_cube_size[0]\n",
    "                    x_start_output=i#只使用了x_start_input没有用x_start_output\n",
    "                    x_end_output=i+stride[0]#同\n",
    "                else:\n",
    "                    x_start_input=img_shape[0]-crop_cube_size[0]\n",
    "                    x_end_input=img_shape[0]\n",
    "                    x_start_output=i\n",
    "                    x_end_output=img_shape[0]\n",
    "\n",
    "                #这部分代码的作用是计算y轴方向上需要裁剪的区域的起始和结束位置。\n",
    "                # 如果当前位置j+crop_cube_size[1]小于等于img_shape[1]，说明可以完整地取出crop_cube_size[1]大小的区域，\n",
    "                # 因此y_start_input从j开始，y_end_input从j+crop_cube_size[1]开始，y_start_output和y_end_output也相同。\n",
    "                if j+crop_cube_size[1]<=img_shape[1]:\n",
    "                    y_start_input=j\n",
    "                    y_end_input=j+crop_cube_size[1]\n",
    "                    y_start_output=j\n",
    "                    y_end_output=j+stride[1]\n",
    "                else:\n",
    "                # 如果当前位置j+crop_cube_size[1]大于img_shape[1]，说明无法完整地取出crop_cube_size[1]大小的区域\n",
    "                # 因此y_start_input为img_shape[1]-crop_cube_size[1]，y_end_input为img_shape[1]，\n",
    "                # 表示从img_shape[1]-crop_cube_size[1]位置开始取到img_shape[1]位置，\n",
    "                # 此时y_start_output为j，表示当前位置j之前的部分已经被裁剪过了，\n",
    "                # y_end_output为img_shape[1]，表示当前位置j到img_shape[1]位置之间的部分会被裁剪。\n",
    "                    y_start_input=img_shape[1]-crop_cube_size[1]\n",
    "                    y_end_input=img_shape[1]\n",
    "                    y_start_output=j\n",
    "                    y_end_output=img_shape[1]\n",
    "                \n",
    "                if k+crop_cube_size[2]<=img_shape[2]:\n",
    "                    z_start_input=k\n",
    "                    z_end_input=k+crop_cube_size[2]\n",
    "                    z_start_output=k\n",
    "                    z_end_output=k+stride[2]\n",
    "                else:\n",
    "                    z_start_input=img_shape[2]-crop_cube_size[2]\n",
    "                    z_end_input=img_shape[2]\n",
    "                    z_start_output=k\n",
    "                    z_end_output=img_shape[2]\n",
    "                #最后，我们将裁剪后的图像添加到 crop_list 中，并递增计数器 count。循环结束后，我们将 crop_list 返回。\n",
    "                crop_temp=input_img[x_start_input:x_end_input, y_start_input:y_end_input, z_start_input:z_end_input]\n",
    "                crop_list.append(np.array(crop_temp, dtype=np.float))\n",
    "                \n",
    "                count=count+1\n",
    "                \n",
    "    return crop_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3c2496",
   "metadata": {},
   "source": [
    "#### pre crop LIDC-IDRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a22642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop_cube_size=(256, 256, 256)\n",
    "# stride=(128,128,128)\n",
    "\n",
    "# # -----INPUT-----\n",
    "# output_file_path = \"Precrop_dataset_for_LIDC-IDRI\"\n",
    "\n",
    "# if not os.path.exists(output_file_path+\"/image/\"):\n",
    "#     os.makedirs(output_file_path+\"/image/\")\n",
    "\n",
    "# if not os.path.exists(output_file_path+\"/label/\"):\n",
    "#     os.makedirs(output_file_path+\"/label/\")\n",
    "\n",
    "# raw_data_dict = LIDC_IDRI_data_dict\n",
    "# # -----END-----\n",
    "\n",
    "# for i, case in enumerate(raw_data_dict.keys()):\n",
    "#     raw_img = io.imread(raw_data_dict[case][\"image\"], plugin='simpleitk')\n",
    "#     label_img = io.imread(raw_data_dict[case][\"label\"], plugin='simpleitk')\n",
    "    \n",
    "#     raw_img_crop_list = crop_one_3d_img(raw_img, crop_cube_size=crop_cube_size, stride=stride)\n",
    "#     label_img_crop_list = crop_one_3d_img(label_img, crop_cube_size=crop_cube_size, stride=stride)\n",
    "    \n",
    "#     assert len(raw_img_crop_list)==len(label_img_crop_list)\n",
    "    \n",
    "#     for idx in range(len(raw_img_crop_list)):\n",
    "#         print(\"progress: \"+str(idx)+\"th crop | \"+str(i)+\"th 3d img: \"+str(case), end=\"\\r\")\n",
    "        \n",
    "#         #sitk.WriteImage(sitk.GetImageFromArray(raw_img_crop_list[idx]), output_file_path+\"/image/\"+case+\"_\"+str(idx)+\".nii.gz\")\n",
    "#         #sitk.WriteImage(sitk.GetImageFromArray(label_img_crop_list[idx]), output_file_path+\"/label/\"+case+\"_\"+str(idx)+\".nii.gz\")\n",
    "        \n",
    "#         np.save(output_file_path+\"/image/\"+case+\"_\"+str(idx)+\".npy\", raw_img_crop_list[idx])\n",
    "#         np.save(output_file_path+\"/label/\"+case+\"_\"+str(idx)+\".npy\", label_img_crop_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176ad24",
   "metadata": {},
   "source": [
    "#### pre crop EXACT09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50f93174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5428/1438904564.py:42: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  print('crop one 3d img progress : '+str(np.int(count/total*100))+'%', end='\\r')\n",
      "/tmp/ipykernel_5428/1438904564.py:85: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  crop_list.append(np.array(crop_temp, dtype=np.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 319th crop | 19th 3d img: EXACT09_CASE20\r"
     ]
    }
   ],
   "source": [
    "crop_cube_size=(128,128,128)\n",
    "stride=(64,64,64)\n",
    "\n",
    "# -----INPUT-----\n",
    "output_file_path = \"Precrop_dataset_for_EXACT09\"#在这个文件夹下\n",
    "\n",
    "if not os.path.exists(output_file_path+\"/image/\"):\n",
    "    os.makedirs(output_file_path+\"/image/\")\n",
    "\n",
    "if not os.path.exists(output_file_path+\"/label/\"):\n",
    "    os.makedirs(output_file_path+\"/label/\")\n",
    "\n",
    "raw_data_dict = EXACT09_data_dict\n",
    "# -----END-----\n",
    "\n",
    "for i, case in enumerate(raw_data_dict.keys()):\n",
    "    raw_img = io.imread(raw_data_dict[case][\"image\"], plugin='simpleitk')\n",
    "    label_img = io.imread(raw_data_dict[case][\"label\"], plugin='simpleitk')\n",
    "    \n",
    "    raw_img_crop_list = crop_one_3d_img(raw_img, crop_cube_size=crop_cube_size, stride=stride)#用上面那个函数裁剪\n",
    "    label_img_crop_list = crop_one_3d_img(label_img, crop_cube_size=crop_cube_size, stride=stride)\n",
    "    \n",
    "    assert len(raw_img_crop_list)==len(label_img_crop_list)\n",
    "    \n",
    "    for idx in range(len(raw_img_crop_list)):\n",
    "        print(\"progress: \"+str(idx)+\"th crop | \"+str(i)+\"th 3d img: \"+str(case), end=\"\\r\")\n",
    "        \n",
    "        #sitk.WriteImage(sitk.GetImageFromArray(raw_img_crop_list[idx]), output_file_path+\"/image/\"+case+\"_\"+str(idx)+\".nii.gz\")\n",
    "        #sitk.WriteImage(sitk.GetImageFromArray(label_img_crop_list[idx]), output_file_path+\"/label/\"+case+\"_\"+str(idx)+\".nii.gz\")\n",
    "        \n",
    "        np.save(output_file_path+\"/image/\"+case+\"_\"+str(idx)+\".npy\", raw_img_crop_list[idx])#保存\n",
    "        np.save(output_file_path+\"/label/\"+case+\"_\"+str(idx)+\".npy\", label_img_crop_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ba1312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 EXACT09_CASE01\n",
      "1 EXACT09_CASE02\n",
      "2 EXACT09_CASE03\n",
      "3 EXACT09_CASE04\n",
      "4 EXACT09_CASE05\n",
      "5 EXACT09_CASE06\n",
      "6 EXACT09_CASE07\n",
      "7 EXACT09_CASE08\n",
      "8 EXACT09_CASE09\n",
      "9 EXACT09_CASE10\n",
      "10 EXACT09_CASE11\n",
      "11 EXACT09_CASE12\n",
      "12 EXACT09_CASE13\n",
      "13 EXACT09_CASE14\n",
      "14 EXACT09_CASE15\n",
      "15 EXACT09_CASE16\n",
      "16 EXACT09_CASE17\n",
      "17 EXACT09_CASE18\n",
      "18 EXACT09_CASE19\n",
      "19 EXACT09_CASE20\n",
      "(587, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "crop_cube_size=(128,128,128)\n",
    "stride=(64,64,64)\n",
    "\n",
    "# -----INPUT-----\n",
    "output_file_path = \"Precrop_dataset_for_EXACT09\"#在这个文件夹下\n",
    "\n",
    "if not os.path.exists(output_file_path+\"/image/\"):\n",
    "    os.makedirs(output_file_path+\"/image/\")\n",
    "\n",
    "if not os.path.exists(output_file_path+\"/label/\"):\n",
    "    os.makedirs(output_file_path+\"/label/\")\n",
    "\n",
    "raw_data_dict = EXACT09_data_dict\n",
    "# -----END-----\n",
    "\n",
    "# for i, case in enumerate(raw_data_dict.keys()):\n",
    "#     print(i,case)\n",
    "case1='EXACT09_CASE01'\n",
    "raw_img = io.imread(raw_data_dict[case1][\"image\"], plugin='simpleitk')\n",
    "label_img = io.imread(raw_data_dict[case1][\"label\"], plugin='simpleitk')\n",
    "print(raw_img.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "93b8bddce1ae77ec23f290c2363ef3152268ce7a5780cd85528e7b45d8c4cc74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
